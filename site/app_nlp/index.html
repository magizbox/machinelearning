<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Natural Language Processing - Machine Learning</title>
        <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../css/font-awesome-4.5.0.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="../css/highlight.css">
        <link href="../components/magiz-c-book/src/book.css" rel="stylesheet">
        <link href="../components/magiz-c-course/src/course.css" rel="stylesheet">
        <link href="../components/magiz-c-video/src/video.css" rel="stylesheet">
        <link href="../components/magiz-c-benchmark/src/benchmark.css" rel="stylesheet">
        <link href="../components/magiz-c-paper/src/paper.css" rel="stylesheet">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->
	
	<script src="../js/jquery-1.10.2.min.js"></script>
        <script src="../js/bootstrap-3.0.3.min.js"></script>
        <script src="../js/highlight.pack.js"></script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="..">Machine Learning</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                    <li >
                        <a href=".."><span class='fa fa-home'></span> Home</a>
                    </li>
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><span class='fa fa-book'></span> Learn <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
  <li class="dropdown-submenu">
    <a href="#">Machine Learning Process</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../process/">Overview</a>
</li>
            
<li >
    <a href="../problem/">Problem Definition</a>
</li>
            
<li >
    <a href="../gathering/">Gathering</a>
</li>
            
<li >
    <a href="../preprocessing/">Preprocessing</a>
</li>
            
<li >
    <a href="../model_building/">Model Building</a>
</li>
            
<li >
    <a href="../evaluation/">Evaluation</a>
</li>
    </ul>
  </li>
                            
<li >
    <a href="../models/">Machine Learning Problems</a>
</li>
                            
<li >
    <a href="../learn/">How to learn a ML algorithm?</a>
</li>
                            
<li >
    <a href="../model_regression/">Regression</a>
</li>
                            
<li >
    <a href="../model_classification/">Classification</a>
</li>
                            
<li >
    <a href="../model_clustering/">Clustering</a>
</li>
                            
<li >
    <a href="../ensemble/">Ensemble</a>
</li>
                            
<li >
    <a href="../app_reduction/">Dimensionality Reduction</a>
</li>
                            
<li >
    <a href="../app_anomaly/">Anomaly Detection</a>
</li>
                            
  <li class="dropdown-submenu">
    <a href="#">Application</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../app_recommendation/">Recommendation System</a>
</li>
            
<li class="active">
    <a href="./">Natural Language Processing</a>
</li>
            
<li >
    <a href="../app_vision/">Computer Vision</a>
</li>
    </ul>
  </li>
                            
<li >
    <a href="../qanda/">Q&A</a>
</li>
                        </ul>
                    </li>
                </ul>

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                    <li >
                        <a rel="next" href="../app_recommendation/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../app_vision/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
            </ul>
        </div>
    </div>
</div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#natural-language-processing-nlp">Natural Language Processing (NLP)</a></li>
            <li><a href="#deep-learning">Deep Learning</a></li>
            <li><a href="#courses">Courses</a></li>
        <li class="main "><a href="#pos-tagging">POS Tagging</a></li>
            <li><a href="#methods">Methods</a></li>
        <li class="main "><a href="#textual-entailment">Textual entailment</a></li>
        <li class="main "><a href="#language-modeling">Language Modeling</a></li>
        <li class="main "><a href="#n-gram-model">N-Gram Model</a></li>
        <li class="main "><a href="#tfidf">Tfidf</a></li>
            <li><a href="#python-lab">Python Lab</a></li>
            <li><a href="#tf">Tf</a></li>
        <li class="main "><a href="#unigram-bigram-model">Unigram Bigram Model</a></li>
        <li class="main "><a href="#near-duplicates">Near-Duplicates</a></li>
        <li class="main "><a href="#word2vec">Word2vec</a></li>
            <li><a href="#installation">Installation</a></li>
            <li><a href="#lab">Lab</a></li>
        <li class="main "><a href="#document-classification">Document Classification</a></li>
        <li class="main "><a href="#process-1">Process 1</a></li>
        <li class="main "><a href="#document-clustering">Document Clustering</a></li>
        <li class="main "><a href="#task-related-terms-in-documents">Task: Related terms in documents</a></li>
        <li class="main "><a href="#topic-models-lda">Topic Models: LDA</a></li>
        <li class="main "><a href="#sentiment-analysis">Sentiment Analysis</a></li>
        <li class="main "><a href="#name-entity-recognization">Name Entity Recognization</a></li>
            <li><a href="#tutorial">Tutorial</a></li>
        <li class="main "><a href="#relation-extraction">Relation Extraction</a></li>
        <li class="main "><a href="#sentence-segmentation">Sentence Segmentation</a></li>
        <li class="main "><a href="#english-nlp">English NLP</a></li>
        <li class="main "><a href="#tools">Tools</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h1 id="natural-language-processing-nlp">Natural Language Processing (NLP)</h1>
<p><img alt="" src="https://www.ibm.com/developerworks/mydeveloperworks/blogs/nlp/resource/nlp-shakespeare.jpg" /></p>
<blockquote>
<p>Is paris capital of France?
YES</p>
</blockquote>
<h3 id="deep-learning">Deep Learning</h3>
<p><a href="http://u.cs.biu.ac.il/~yogo/nnlp.pdf">A Primer on Neural Network Models for Natural Language Processing</a></p>
<h3 id="courses">Courses</h3>
<ul>
<li>CS224n: Natural Language Processing (<a href="http://web.stanford.edu/class/cs224n/index.shtml">website</a>, <a href="https://www.youtube.com/watch?v=GZhhA3DBs9o&amp;list=PLgtM85Maly3n2Fp1gJVvqb0bTC39CPn1N">video</a>)</li>
<li><a href="http://cs224d.stanford.edu/">CS224d: Deep Learning for Natural Language Processing</a></li>
</ul>
<h1 id="pos-tagging">POS Tagging</h1>
<p><img alt="" src="https://www.safaribooksonline.com/library/view/natural-language-annotation/9781449332693/figs/web/nlml_0106.png" /></p>
<p>A Part-Of-Speech Tagger (POS Tagger) is a piece of software that reads text in some language and assigns parts of speech to each word (and other token), such as noun, verb, adjective, etc., although generally computational applications use more fine-grained POS tags like 'noun-plural'.</p>
<h2 id="methods">Methods</h2>
<ol>
<li>Sequence Classification <sup id="fnref:1"><a class="footnote-ref" href="#fn:1" rel="footnote">1</a></sup></li>
</ol>
<h1 id="textual-entailment">Textual entailment</h1>
<p><img alt="" src="http://image.slidesharecdn.com/acl-tutorial-on-textual-entailment2964/95/acl-tutorial-on-textual-entailment-17-728.jpg?cb=1278312611" /></p>
<p>Textual entailment (TE) in natural language processing is a directional relation between text fragments. The relation holds whenever the truth of one text fragment follows from another text. In the TE framework, the entailing and entailed texts are termed text (t) and hypothesis (h), respectively. Textual entailment is not the same as pure logical entailment- it has a more relaxed definition: "t entails h" (t ⇒ h) if, typically, a human reading t would infer that h is most likely true. The relation is directional because even if "t entails h", the reverse "h entails t" is much less certain. <sup id="fnref:1"><a class="footnote-ref" href="#fn:1" rel="footnote">1</a></sup></p>
<h1 id="language-modeling">Language Modeling</h1>
<p>Language Models <sup id="fnref:1"><a class="footnote-ref" href="#fn:1" rel="footnote">1</a></sup></p>
<ul>
<li>N-Gram</li>
<li><a href="http://magizbox.com/?p=3843">Tfidf</a></li>
<li><a href="http://magizbox.com/?p=3083">word2vec</a></li>
</ul>
<h1 id="n-gram-model">N-Gram Model</h1>
<h1 id="tfidf">Tfidf</h1>
<p>tf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in information retrieval and text mining. The tf-idf value increases proportionally to the number of times a word appears in the document, but is offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general. <sup id="fnref:1"><a class="footnote-ref" href="#fn:1" rel="footnote">1</a></sup></p>
<p><code>tf</code> (Term Frequence)</p>
<p><code>idf</code> (Inverse Document Frequency)</p>
<p>How term is important in corpus?</p>
<p><code>tf-idf</code> - Term frequency–Inverse document frequency</p>
<p>How term is important in document?</p>
<h2 id="python-lab">Python Lab</h2>
<p>We exam a corpus with 2 documents</p>
<ul>
<li>Doc 1: <em>this is a sample</em></li>
<li>Doc 2: <em>this is another sample</em></li>
</ul>
<h2 id="tf">Tf</h2>
<table>
<tr>
<td>Vocab</td>
<td>$latex tf=f_{t,d}$</td>
</tr>
<tr>
<td>this</td>
<td></td>
</tr>
<tr>
<td>is</td>
<td></td>
</tr>
<tr>
<td>a</td>
<td></td>
</tr>
<tr>
<td>sample</td>
<td></td>
</tr>
<tr>
<td>another</td>
<td></td>
</tr>
<tr>
</table>

<p>[code lang="python"]
from sklearn.feature_extraction.text import TfidfVectorizer
X = ["this is a sample", "this is another example"]
vectorizer = TfidfVectorizer()
vectorizer.fit_transform(X)
[/code]</p>
<p>Now we find what are important terms of this corpus:</p>
<p>[code lang="python"]
for term in vectorizer.vocabulary_.keys():
    index = vectorizer.vocabulary_[term]
    score = vectorizer.<em>tfidf.idf</em>[index]
    print "%10s: %2.2f" % (term, score)
[/code]
[code]
      this: 1.00
    sample: 1.41
        is: 1.00
   example: 1.41
   another: 1.41
[/code]</p>
<p><code>sample</code>,<code>example</code> and <code>another</code> are important term in this corpus.</p>
<p>Next, we look at 2 more documents, and find what are import terms in those documents</p>
<p>[code lang="python"]
print vectorizer.vocabulary_
print vectorizer.transform(["another sample", "this example"])
[/code]</p>
<p>[code]
{u'this': 4, u'sample': 3, u'is': 2, u'example': 1, u'another': 0}
  (0, 3)    0.707106781187
  (0, 0)    0.707106781187
  (1, 4)    0.579738671538
  (1, 1)    0.814802474667
[/code]</p>
<p>In document 1, <code>sample</code> (index 3) and <code>another</code> (index 0) are equally, but in document 2, <code>example</code> (index 0) is more important than <code>this</code> (index 4). The reasons is <code>this</code> appears in whole corpus, there for it doesn't tell us any more information.</p>
<h1 id="unigram-bigram-model">Unigram Bigram Model</h1>
<h1 id="near-duplicates">Near-Duplicates</h1>
<p>Simhash</p>
<p><a href="http://stackoverflow.com/questions/1908330/simhash-implementation-in-java">Detecting Near-Duplicates for Web Crawling</a></p>
<p><a href="http://aneurone.blogspot.com/2012/09/simhash.html">SimHash</a></p>
<h1 id="word2vec">Word2vec</h1>
<h3 id="installation">Installation</h3>
<p>[code]
conda install gensim
[/code]</p>
<h3 id="lab">Lab</h3>
<p>Step 1: I download some articles about Hà Nội (the captial of Việt Nam)</p>
<p>Step 2: I use vnTokenizer to tokenize words</p>
<p>Step 3: I train Word2Vec model</p>
<h4 id="resources">Resources</h4>
<p>Word2vec-pride-vis <small>[code]<a href="https://github.com/arnicas/word2vec-pride-vis">/code</a>, <a href="http://www.ghostweather.com/files/word2vecpride/">interactive visualization</a></small></p>
<h1 id="document-classification">Document Classification</h1>
<p>Document classification or document categorization is a problem in library science, information science and computer science. The task is to assign a document to one or more classes or categories. This may be done "manually" (or "intellectually") or algorithmically. The intellectual classification of documents has mostly been the province of library science, while the algorithmic classification of documents is mainly in information science and computer science. The problems are overlapping, however, and there is therefore interdisciplinary research on document classification. <sup id="fnref:2"><a class="footnote-ref" href="#fn:2" rel="footnote">2</a></sup></p>
<h1 id="process-1">Process <sup id="fnref:1"><a class="footnote-ref" href="#fn:1" rel="footnote">1</a></sup></h1>
<ul>
<li>Step 1: Generate document features: TFidf Model,</li>
<li>Step 2: Fit features to a classifier: Multinomial Naive Bayes, Maxent Classifier, DecisionTreeClassifier</li>
<li>Step 3: Evaluating: use F1 score</li>
</ul>
<h1 id="document-clustering">Document Clustering</h1>
<p>Document clustering (or text clustering) is the application of cluster analysis to textual documents. It has applications in automatic document organization, topic extraction and fast information retrieval or filtering. <sup id="fnref:1"><a class="footnote-ref" href="#fn:1" rel="footnote">1</a></sup></p>
<ul>
<li>TopicModel &gt; LDA</li>
</ul>
<h1 id="task-related-terms-in-documents">Task: Related terms in documents</h1>
<p><a href="http://stackoverflow.com/questions/7544266/algorithm-to-find-related-words-in-a-text">Algorithm to find related words in a text</a>
<a href="http://stackoverflow.com/questions/34650672/how-to-find-related-terms-in-documents">How to find related terms in documents</a></p>
<h1 id="topic-models-lda">Topic Models: LDA</h1>
<h1 id="sentiment-analysis">Sentiment Analysis</h1>
<h1 id="name-entity-recognization">Name Entity Recognization</h1>
<p><img alt="" src="https://researchkb.files.wordpress.com/2014/02/ner.png" /></p>
<p>Named-entity recognition (NER) (also known as entity identification, entity chunking and entity extraction) is a subtask of information extraction that seeks to locate and classify elements in text into pre-defined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc. <sup id="fnref:1"><a class="footnote-ref" href="#fn:1" rel="footnote">1</a></sup></p>
<h2 id="tutorial">Tutorial</h2>
<p><a href="https://www.youtube.com/watch?v=mbMrRT5Osbk">9 - 3 - Sequence Models for Named Entity Recognition-NLP-Professor Dan Jurafsky &amp; Chris Manning</a></p>
<h1 id="relation-extraction">Relation Extraction</h1>
<h1 id="sentence-segmentation">Sentence Segmentation</h1>
<p><img alt="" src="https://s3.amazonaws.com/work-sample-images/blog_segmentation.jpg" /></p>
<p>Sentence segmentation is the problem of dividing a string of written language into its component sentences. In English and some other languages, using punctuation, particularly the full stop/period character is a reasonable approximation. However even in English this problem is not trivial due to the use of the full stop character for abbreviations, which may or may not also terminate a sentence.</p>
<p>For example Mr. is not its own sentence in "Mr. Smith went to the shops in Jones Street." When processing plain text, tables of abbreviations that contain periods can help prevent incorrect assignment of sentence boundaries.</p>
<p>As with word segmentation, not all written languages contain punctuation characters which are useful for approximating sentence boundaries.</p>
<h1 id="english-nlp">English NLP</h1>
<p>Dictionary / Wordnet <sup id="fnref:1"><a class="footnote-ref" href="#fn:1" rel="footnote">1</a></sup></p>
<p>Corpus</p>
<ul>
<li><a href="https://dumps.wikimedia.org/enwiki/">English Wikipedia</a></li>
</ul>
<h1 id="tools">Tools</h1>
<ul>
<li><a href="">gensims</a></li>
<li><a href="">wiki</a></li>
</ul>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p><a href="http://stackoverflow.com/questions/2667057/english-dictionary-as-txt-or-xml-file-with-support-of-synonyms">English dictionary as txt or xml file with support of synonyms</a>&#160;<a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p><a href="https://en.wikipedia.org/wiki/Document_classification">Document classification</a>&#160;<a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div></div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>var base_url = '..';</script>
        <script data-main="../mkdocs/js/search.js" src="../mkdocs/js/require.js"></script>
        <script src="../js/base.js"></script>
        <script src="../components/magiz-c-book/src/gspreadsheet.js"></script>
        <script src="../components/underscore/underscore.js"></script>
        <script src="../components/magiz-c-paper/src/paper.js"></script>
        <script src="../components/magiz-c-course/src/course.js"></script>
        <script src="../components/magiz-c-benchmark/src/benchmark.js"></script>
        <script src="../components/magiz-c-benchmark/src/bootstrap-popup.js"></script>
        <script src="../components/magiz-c-book/src/book.js"></script>
        <script src="../components/magiz-c-video/src/video.js"></script>
        <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
